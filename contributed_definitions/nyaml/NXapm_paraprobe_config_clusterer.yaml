category: application
doc: |
  Configuration of a paraprobe-clusterer tool run in atom probe microscopy.
symbols:
  doc: The symbols used in the schema to specify e.g. dimensions of arrays.
  # n_positions: Number of position values.
  # n_disjoint_clusters: Number of disjoint cluster.
  n_ivecmax: Maximum number of atoms per molecular ion. Should be 32 for paraprobe.
  n_clust_algos: Number of clustering algorithms used.
  n_ions: Number of different iontypes to distinguish during clustering.
NXapm_paraprobe_config_clusterer:
  (NXentry):
    # by default for appdefs the value of the exists keyword is required
    # unless it is explicitly specified differently
    \@version:
      doc: Version specifier of this application definition.
    definition:
      doc: Official NeXus NXDL schema with which this file was written.
      enumeration: [NXapm_paraprobe_config_clusterer]
    program:
      doc: |
        Given name of the program/software/tool with which this NeXus
        (configuration) file was generated.
      \@version:
        doc: |
          Ideally program version plus build number, or commit hash or description
          of ever persistent resources where the source code of the program and
          build instructions can be found so that the program can be configured
          ideally in such a manner that the result of this computational process
          is recreatable in the same deterministic manner.
    time_stamp(NX_DATE_TIME):
      doc: |
        ISO 8601 formatted time code with local time zone offset to UTC
        information included when this configuration file was created.
    analysis_identifier:
      exists: optional
      doc: |
        Ideally, a (globally persistent) unique identifier for referring
        to this analysis.
    analysis_description:
      exists: optional
      doc: Possibility for leaving a free-text description about this analysis.
    number_of_processes(NX_UINT):
      doc: |
        How many tasks to perform?
      unit: NX_UNITLESS

    cameca_to_nexus(NXprocess):
      exists: optional
      doc: |
        This process maps results from cluster analyses performed with IVAS/APSuite
        into an interoperable representation. Specifically in this process
        paraprobe-clusterer takes results from clustering methods from other tools
        of the APM community, like IVAS/APSuite. These results are usually reported
        in two ways. Either as an explicit list of reconstructed ion positions.
        In the case of IVAS these positions are reported through a text file
        with a cluster label for each position.
        
        Alternatively, the list of positions is reported, as it is the case for
        AMETEK (IVAS/AP Suite) but the cluster labels are specified implicitly
        only in the following way: The mass-to-charge-state ratio column of a
        what is effectively a file formatted like POS is used to assign a hypothetical
        mass-to-charge value which resolves a floating point representation
        of the cluster ID.
        
        Another case can occur where all disjoint floating point values,
        i.e. here cluster labels, are reported and then a dictionary is created
        how each value matches to a cluster ID.
        
        In general the cluster ID zero is reserved for marking the dataset
        as to not be assigned to any cluster. Therefore, indices of disjoint
        clusters start at 1.
      dataset(NXapm_input_reconstruction):
        filename:
          \@version:
        dataset_name_reconstruction:
        dataset_name_mass_to_charge:
          doc: |
            AMETEK/Cameca results of cluster analyses, like with the maximum-
            separation (MS) method clustering algorithm `J. Hyde et al. <https://doi.org/10.1557/PROC-650-R6.6>`_  
            are stored as an improper POS file: This is a matrix of floating
            point quadruplets, one for each ion and as many quadruplets as
            ions were investigated. The first three values encode the position
            of the ion. The fourth value is an improper mass-to-charge-state-ratio
            value which encodes the integer identifier of the cluster as a floating
            point number.
      # mapping_method:
      #   doc: |
      #     How should cluster labels be created from the cluster_labels information
      #     especially when these areNcluste floating point values.
      #  enumeration: [take_as_is, use_dictionary]
      # mapping_dictionary_keyword(NX_NUMBER):
      #   doc: |
      #     The list of all keywords of a dictionary which maps implicit cluster
      #     indices like those from IVAS/APSuite which were0ass-to-charge-state ratios.
      #   unit: NX_UNITLESS
      #   dimensions:
      #     rank: 1
      #     dim: [[1, n_disjoint_clusters]]
      # mapping_dictionary_value(NX_UINT):
      #   doc: |
      #     The list of all values of a dictionary which maps implicit cluster
      #     indices like those from IVAS/APSuite which were0ass-to-charge-state ratios.
      #     The sequences of mapping_dictionary_keyword and mapping_dictionary_value
      #     have to match.
      #   unit: NX_UNITLESS
      #   dimensions:
      #     rank: 1
      #     dim: [[1, n_disjoint_clusters]]
      recover_evaporation_id(NX_BOOLEAN):
        doc: |
          Specifies if the tool should try to recover for each position the closest
          matching position from dataset/dataset_name_reconstruction (within
          floating point accuracy). This can be useful for instance when users
          wish to recover the original evaporation ID, which IVAS/AP Suite drops
          for instance when writing their *.indexed.* cluster results POS files.
      # recover_bitmask(NX_BOOLEAN):
      #   doc: |
      #     Specifies if the tool should try to recover, after a recovery of the
      #     evaporation IDs a bitmask which identifies which of the positions
      #     in dataset/dataset/dataset_name_reconstruction where covered
      #     by the IVAS/APSuite cluster analysis. This can be useful to recover
      #     the region of interest.

    cluster_analysis(NXprocess):
      exists: [min, 0, max, 1]
      doc: |
        This process performs a cluster analysis on a reconstructed dataset
        or a portion of the reconstruction.
      dataset(NXapm_input_reconstruction):
        filename:
          \@version:
        dataset_name_reconstruction:
        dataset_name_mass_to_charge:
      iontypes(NXapm_input_ranging):
        filename:
          \@version:
        group_name_iontypes:
      ion_to_edge_distances(NXprocess):
        exists: optional
        doc: |
          The tool enables to inject precomputed distance information for each
          point/ion which can be used for further post-processing and analysis.
        filename:
          doc: Name of an HDF5 file which contains the ion distances.
          \@version:
            doc: |
              Version identifier of the file such as a secure hash which documents
              the binary state of the file to add an additional layer of
              reproducibility from which file specifically contains these data.
        dataset_name:
          doc: Absolute HDF5 path to the dataset with distance values for each ion.

      spatial_filter(NXspatial_filter):
        exists: optional
        windowing_method:
          exists: required
          enumeration: [entire_dataset]  # ##MK::nothing implemented so far
        (NXcg_ellipsoid_set):
          exists: optional
          dimensionality(NX_POSINT):
          cardinality(NX_POSINT):
          identifier_offset(NX_INT):
          center(NX_NUMBER):
          half_axes_radii(NX_NUMBER):
          orientation(NX_NUMBER):
        (NXcg_cylinder_set):
          exists: optional
          dimensionality(NX_POSINT):
          cardinality(NX_POSINT):
          identifier_offset(NX_INT):
          center(NX_NUMBER):
          height(NX_NUMBER):
          radii(NX_NUMBER):
        (NXcg_hexahedron_set):
          exists: optional
          dimensionality(NX_POSINT):
          cardinality(NX_POSINT):
          identifier_offset(NX_INT):
          hexahedra(NXcg_face_list_data_structure):
        (NXcs_filter_boolean_mask):
          exists: optional
          number_of_objects(NX_UINT):
          bitdepth(NX_UINT):
          mask(NX_UINT):
          identifier(NX_UINT):
      evaporation_id_filter(NXsubsampling_filter):
        exists: optional
      iontype_filter(NXmatch_filter):
        exists: optional
      hit_multiplicity_filter(NXmatch_filter):
        exists: optional

      # clustering_algorithm(NX_CHAR):
      #   doc: |
      #     Name of the clustering algorithm used.
      #   enumeration: [dbscan]  # , optics, hpdbscan]
      #   dimensions:
      #     rank: 1
      #     dim: [[1, n_clust_algos]]
      ion_type_filter(NX_CHAR):
        doc: |
          How should iontypes be interpreted/considered during the cluster analysis.
          Different options exist how iontypes are interpreted (if considered at all)
          given an iontype represents in general a (molecular) ion with different isotopes
          that have individually different multiplicity.
          
          The value resolve_all will set an ion active in the analysis
          regardless of which iontype it is.
          The value resolve_unknown will set an ion active when it is of the
          UNKNOWNTYPE.
          The value resolve_ion will set an ion active if it is of the
          specific iontype, irregardless of its elemental or isotopic details.
          The value resolve_element will set an ion active, and most importantly,
          account as many times for it, as the (molecular) ion contains
          atoms of elements in the whitelist ion_query_isotope_vector.
          The value resolve_isotope will set an ion active, and most importantly,
          account as many times for it, as the (molecular) ion contains isotopes
          in the whitelist ion_query_isotope_vector.
          
          In effect, ion_query_isotope_vector acts as a whitelist to filter
          which ions are considered as source ions of the correlation statistics
          and how the multiplicity of each ion will be factorized.
          
          This is relevant as in atom probe we have the situation that a ion
          of a molecular ion with more than one nuclid, say Ti O for example
          is counted such that although there is a single TiO molecular ion
          at a position that the cluster has two members. This multiplicity
          affects the size of the feature and chemical composition.
        # enumeration: [resolve_all, resolve_unknown, resolve_ion, resolve_element, resolve_isotope]
        enumeration: [resolve_element]  # specify further details
      ion_query_isotope_vector(NX_UINT):
        doc: |
          Matrix of isotope vectors, as many as rows as different candidates
          for iontypes should be distinguished as possible source iontypes.
          In the simplest case, the matrix contains only the proton number
          of the element in the row, all other values set to zero.
          Combined with ion_query_type_source set to resolve_element this will
          recover usual spatial correlation statistics like the 1NN C-C
          spatial statistics.
        unit: NX_UNITLESS
        dimensions:
          rank: 2
          dim: [[1, n_ions], [2, n_ivecmax]]
      dbscan(NXprocess):
        doc: |
          Settings for DBScan clustering algorithm. For original details about the
          algorithms and (performance-relevant) details consider:
          
          * `M. Ester et al. <https://dx.doi.org/10.5555/3001460.3001507>`_  
          * `M. Götz et al. <https://dx.doi.org/10.1145/2834892.2834894>`_  
          
          For details about how the DBScan algorithms is the key behind the
          specific modification known as the maximum-separation method in the
          atom probe community consider `E. Jägle et al. <https://dx.doi.org/10.1017/S1431927614013294>`_  
        high_throughput_method(NX_CHAR):
          doc: |
            Strategy how runs are performed with different parameter:
            
            * For tuple as many runs are performed as parameter values.
            * For combinatorics individual parameter arrays are looped over.
            
            As an example we may define eps with ten entries and min_pts with
            three entries. If high_throughput_method is tuple the analysis is
            invalid as we have an insufficient number of min_pts for the ten
            eps values.
            By contrast, for combinatorics paraprobe-clusterer will run three
            individual min_pts runs for each eps value, resulting in a total
            of 30 analyses.
            As an example the DBScan analysis reported in `M. Kühbach et al. <https://dx.doi.org/10.1038/s41524-020-00486-1>`_
            would have defined an array of values np.linspace(0.2, 5.0, nums=241, endpoint=True)
            eps values, min_pts one, and high_throughput_method set to combinatorics.
          enumeration: [tuple, combinatorics]
        eps(NX_FLOAT):
          doc: |
            Array of epsilon (eps) parameter values.
          unit: NX_LENGTH
          dimensions:
            rank: 1
            dim: [[1, i]]
        min_pts(NX_UINT):
          doc: |
            Array of minimum points (min_pts) parameter values.
          unit: NX_UNITLESS
          dimensions:
            rank: 1
            dim: [[1, j]]  # ##MK::has to be i like for eps when high_throughput_method is tuple !
      # THE IDEA BEHIND paraprobe-clusterer is that users can run a number of
      # cluster analyses on their dataset on exactly the same point cloud and under
      # the same conditions

      optics(NXprocess):
        doc: |
          Settings for the OPTICS clustering algorithm.
          
          * `M. Ankerest et al. <https://dx.doi.org/10.1145/304181.304187>`_  
        high_throughput_method(NX_CHAR):
          doc: |
            Strategy how runs are performed with different parameter:
            
            * For tuple as many runs are performed as parameter values.
            * For combinatorics individual parameter arrays are looped over.
            
            See the explanation for the corresponding parameter for dbscan
            processes above-mentioned for further details.
          enumeration: [tuple, combinatorics]
        min_pts(NX_UINT):
          doc: |
            Array of minimum points (min_pts) parameter values.
          unit: NX_UNITLESS
          dimensions:
            rank: 1
            dim: [[1, i]]
        max_eps(NX_FLOAT):
          doc: |
            Array of maximum epsilon (eps) parameter values.
          unit: NX_LENGTH
          dimensions:
            rank: 1
            dim: [[1, j]]
      hdbscan(NXprocess):
        doc: |
          Settings for the HPDBScan clustering algorithm.
          
          * L. McInnes et al. <https://dx.doi.org/10.21105/joss.00205>`_  
          * scikit-learn hdbscan library `<https://hdbscan.readthedocs.io/en/latest/how_hdbscan_works.html>`_  
          
          See also this documentation for details about the parameter.
          Here we use the terminology of the hdbscan documentation.
        high_throughput_method(NX_CHAR):
          doc: |
            Strategy how runs are performed with different parameter:
            
            * For tuple as many runs are performed as parameter values.
            * For combinatorics individual parameter arrays are looped over.
            
            See the explanation for the corresponding parameter for dbscan
            processes above-mentioned for further details.
          enumeration: [tuple, combinatorics]
        min_cluster_size(NX_NUMBER):  # ##MK:? NX_FLOAT
          doc: |
            Array of min_cluster_size parameter values.
          unit: NX_ANY
          dimensions:
            rank: 1
            dim: [[1, i]]
        min_samples(NX_NUMBER):  # ##MK::NX_UINT
          doc: |
            Array of min_samples parameter values.
          unit: NX_ANY
          dimensions:
            rank: 1
            dim: [[1, j]]
        cluster_selection_epsilon(NX_NUMBER):
          doc: |
            Array of cluster_selection parameter values.
          unit: NX_ANY  # ##MK::? but so None as an argument
          dimensions:
            rank: 1
            dim: [[1, k]]
        alpha(NX_NUMBER):  # ##MK:? NX_FLOAT
          doc: |
            Array of alpha parameter values.
          unit: NX_ANY  # ##MK::?
          dimensions:
            rank: 1
            dim: [[1, m]]
      # ADD FURTHER ALGORITHMS, see L. Stephenson for further details
      # e.g. https://doi.org/10.1017/S1431927607070900
